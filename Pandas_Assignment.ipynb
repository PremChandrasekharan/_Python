{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learn_Python.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAkEYetBKAS4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"Demand_txn.txt\")\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read the demand transaction file and print the first 15 rows and dtypes\n",
        "a=df.head(15)\n",
        "print(a)\n",
        "b=df.dtypes\n",
        "print(b)"
      ],
      "metadata": {
        "id": "4UNzOTSXSZrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert the transaction date column to a date column using pd.to_datetime function\n",
        "\n",
        "print(pd.to_datetime(df.Transaction_Date))"
      ],
      "metadata": {
        "id": "m43pNPjYSZwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Subset the dataframe for transaction date greater than '2016-08-01'\n",
        "\n",
        "df_subset=df.loc[df.Transaction_Date > '2016-08-01']\n",
        "df_subset"
      ],
      "metadata": {
        "id": "D0OuShAUSZ7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Look for unique values in Mapped_Sales_Type\n",
        "#unique() - lists the unique items in the column whereas nunique() - gives the count of the unique items in the column.\n",
        "\n",
        "df.Mapped_Sales_Type.unique()"
      ],
      "metadata": {
        "id": "e74Z60btSaCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Subset the entire dataframe, based on the below condition, to a new dataframe and work on the following questions\n",
        "#Condition: Avg_Discount_Percent_On_Discounted_Items should be less than 1.0\n",
        "#Check for sanity if the new dataframe contains Avg_Discount_Percent_On_Discounted_Items greater than or equal to 1.0\n",
        "\n",
        "df.loc[df.Avg_Discount_Percent_On_Discounted_Items > 1.0]"
      ],
      "metadata": {
        "id": "Tu5fx4DCaSfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Groupby 'City', 'Mapped_Sales_Type', 'Mapped_Item_Code', 'Transaction_Date' and perform following aggregate operations on respective columns as mentioned (note: Only one groupby to do all the below aggregations)\n",
        "#Quantity_Sold – sum\n",
        "#Median_Price – median\n",
        "#Effective_Price – median\n",
        "\n",
        "ar=df.groupby(['City', 'Mapped_Item_Code', 'Transaction_Date', 'Mapped_Sales_Type'])\n",
        "ar.Quantity_Sold.sum()\n",
        "ar.Median_Price.median()\n",
        "ar.Effective_Price.median()"
      ],
      "metadata": {
        "id": "Jhoav1bUf4jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display the data for Effective_Price = not null and just print the last 5 rows (hint: use .notnull function)\n",
        "\n",
        "df.Effective_Price.notnull().tail(5)"
      ],
      "metadata": {
        "id": "39JyxLsZj5IO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display the data for city = Chennai AND Mapped_Sales_Type = Delivery and print top 5 records \n",
        "#(hint use loc function to subset, then “&” operator to filter both the above cities)\n",
        "\n",
        "df.groupby(['City', 'Mapped_Sales_Type'])\n",
        "df.loc[:5]"
      ],
      "metadata": {
        "id": "omcId7XulEMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display the data for the column “Day” with values Mon, Tue and Wed (hint: use .isin function)\n",
        "\n",
        "df[df.Day.isin(['Mon','Tue','Wed'])]"
      ],
      "metadata": {
        "id": "zq7y0Ts_rbNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display the data for Percent_Quantity_With_Discount not equal to 0.0 (hint: loc function with != operator)\n",
        "\n",
        "df.loc[df.Percent_Quantity_With_Discount != 0.0]"
      ],
      "metadata": {
        "id": "kV5A83wBtC22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add a column “Range” to the existing dataframe for below condition\n",
        "#1 for Effective_Price > 500\n",
        "#0.5 otherwise\n",
        "\n",
        "df.insert('Range', '1' if df.Effective_Price > 500 else '0.5' if df.Effective_Price < 500)\n",
        "#df.Range=('1' if df.Effective_Price > 500 | '0.5' else df.Effective_Price < 500)"
      ],
      "metadata": {
        "id": "WFNmb88Gtoji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Read the demand transaction file again and perform following operations for practice\n",
        "#Handle the missing values in the column Percent_Quantity_With_Discount with strategy = mean\n",
        "\n"
      ],
      "metadata": {
        "id": "WNschsO7xYjF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}